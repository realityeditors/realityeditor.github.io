<section class="blog" id="blog">
<div class="container">
    <div class="row justify-content-center">
        <div class="col-lg-6">
            <div class="title text-center">
                <h1>Reality-Video-Editor </h1>
                <h2> 高清视频编辑方案 </h1>
                <p></p>
                <p>
                    <a href="https://realityeditor.com.cn/">RealityEditor Team</a>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="container">
    <div>
        <div>
            <img loading="lazy" src="images/product/Demos_video.png" style="width:100%; margin-right:0px; margin-top:0px;">
        </div>
        <hr>
        <div class="row">
			<!-- /section title -->
			<div class="col-md-8 mx-auto">
                <video controls preload="none" width="100%" poster="images/favicon.png">
                    <source src="images/videos/Reality_video_editor.MP4" type="video/mp4">
                </video>
			</div>
		</div>

        <hr>
        <div>
            <br>
            <p>
                我们基于XMem视频分割模型和E2FGVI视频inpainting模型开发了高清视频现实编辑方案。与其他视频编辑方案相比的优势，我们的方案
                1. 不需要针对每个编辑视频进行人为的掩码标注和针对性训练，实现了通用意义的视频编辑；
                2. 实现了像素级别的编辑，编辑的结果考虑了时序，光照，纹理，位置等细节，让效果更真实。
            </p>
            <p>
                我们深入理解现有的短视频市场的特效需求，思考相应的视频编辑技术的挑战，并积极寻求创新方案和框架优化，以达到更高的视频质量与效果。为此，我们选择能够处理长序列的XMem视频分割模型和能够利用时序信息的E2FGVI视频inpainting模型，来实现给定视频和需求的可控视频编辑。
                该模型采用了先进的框架与训练策略，可生成具有高分辨率、平滑的视觉效果、清晰且生动的视频结果。我的视频demo中的四个例子充分展示了本方案的强大效果与广泛应用价值。
            </p>

            <h2>
                模型结构
            </h2>
            <p>
                我们基于AIGC中的XMem视频分割模型和E2FGVI视频inpainting模型，提出了新的高清视频现实编辑方案。利用下图的框架，用户只需要输入相应的视频。并且用点击的方式，指明需要编辑的样例instance，就可以完成他们想要的编辑效果。此过程中不需要人为的掩码标注，也不需要大规模的数据训练，并且我们的方案的编辑效果远远超越传统方法，能够生成以假乱真的编辑特效。
                在框架中，我们在XMem模型和E2FGVI模型的特征空间，利用时序特征建模加强相邻帧的信息交互，并且调整深度特征空间的网络结构来达到轻量级的模型参数量和运行速度。
            </p>

            <div>
                <img loading="lazy" src="images/product/video_pipeline.png" style="width:95%; margin-right:0px; margin-top:10px;">
            </div>
        </div>
    </div>

    <br><br>
    <div>
        <!-- <s2>模型训练和推理使用</s2> -->
        <hr>
        <h2>
            模型训练
        </h2>
        <p>
            我们的通用高清视频编辑方案，首先利用XMem模型来进行任意类别样例的instance分割。XMem在经过大规模语义分割数据集上的预训练之后，能够对视频中的指定区域去进行自动的高精度分割。分割所得的掩码可以被应用于后续的视频inpainting模块。
            而后，我们将分割所得的掩码与输入的视频同时输入到后一阶段的，基于E2FGVI的视频inpainting模型当中。E2FGVI模型具有光流补全，时序特征信息传播以及内容生成的功能，能够在联合预训练中完成不同模块之间的一致性优化。
            经过这样的训练，我们的编辑框架能够具有捕捉绝大部分实际所需的编辑类别的能力，以及生成多样化内容的能力，即能够被用于多个场景下的高清视频编辑。

        </p>

        <h2>
            推理使用
        </h2>
        <p>
            在对特定的视频进行现实编辑的时候，我们首先依照用户点击，用笔触的形式输入用户所需要编辑的物体类别和概念。之后由XMem模型来得到高精度的视频掩码区域分割。之后将掩码结果和输入的视频一起输入到E2FGVI的视频inpainting模型当中，得到现实编辑的最终效果。
        </p>
        <br>
        <hr>
        <h2>
            合作交流
        </h2>
        <p>
            RealityEditor团队致力于为开发者和研究人员提供更多高级的图像应用技术，并着重推动图像合成技术的创新和发展。
            这也是我们开源该项目的最初想法和目的，希望能为更广泛的用户和应用场景带来更广阔的想象空间。
            因此，我们欢迎一切形式的交流、分享和参与，并期待与大家共同实现更多美好的愿景！ 如果您想了解更多细节和技术资料，请访问我们的<a href="https://github.com/Reality-Editor/Composition-Stable-Diffusion">GitHub项目地址</a>。
            <br>
            欢迎通过微信公众号（现实编辑师）联系RealityEditor团队。
        </p>

    </div>
</div>

</section>
